# 一、Java基础

## 1.1 语法篇

### 1.1.1 运算符 &和&&、|和||的区别

&运算符是按位与操作，只有当左右两边操作数对应的⼆进制数为都1时，结果位才为1，否则为0；

|运算符是按位或操作，只要左右两边操作数对应的⼆进制数有⼀个为1的时候，结果位就为1；

当用作逻辑运算时，& 和 && 都可以实现 且 这个功能，两者的区别（`a&b`、`a&&b`）：

- 无论a、b表达式的结果是true还是false，&会对a、b都进行运算；
- &&会先计算a，如果a为false，那么就不会继续计算b，直接返回结果，这称为短路操作；
- 判断语句中推荐使⽤ &&，效率更⾼；

| 和 || 和上面类似，&&和||称之为短路运算符。

### 1.1.2 用最有效率的方法计算2乘以8

使用位移运算符`2<<3`，将⼀个数左移n位，相当于乘以2的n次方，由于位运算是CPU直接⽀持的，所以效率更高。

在JDK源码中的位运算有很多，例如⾯HashMap的默认容量16：

```java
int DEFAULT_INITIAL_CAPACITY = 1 << 4; // aka 16
```

### 1.1.3 交换两个非0的int数值

⽅式⼀：

```java
public static void swap(int a, int b) {
	System.out.printf("a=%d, b=%d",a,b);
	a = a + b;
	b = a - b ;
	a = a - b;
	System.out.printf("\na=%d, b=%d",a,b);
}
```

方式二：

```java
public static void swap2(int a, int b){
	System.out.printf("a=%d, b=%d",a,b);
	a = a^b; // a1 = a^b
	b = b^a; // b = b^a^b
	a = a^b; // a = a1^b = a^b^a
	System.out.printf("\na=%d, b=%d",a,b);
}
```

### 1.1.4 Java数据类型的分类

- 基础数据类型：byte、short、int、long、float、double、char、boolean；
- 引⽤数据类型：其他都是引⽤类型；
  - String和Enum分别是什么类型：引⽤类型；

### 1.1.5 ++前置与后置

定义变量 `int i = 5;`，`return i++;` 和 `return ++i;` 返回结果是什么

- `return i++;`返回5；
- `return ++i;`返回6；

### 1.1.6 == 和equals的区别

- 基本数据类型需要⽤==判断是否相等；
- 引⽤数据类型：
  -  ==⽐较的是是栈中的值：
     -  基本数据类型是变量值；
     -  引用类型是堆中内存对象的地址；
  - equals⽐较的是具体的内容， 可以让开发者去定义什么条件去判断两个对象是否⼀样；

### 1.1.7 final关键字

- 修饰类：表示类不可被继承 ；
- 修饰方法：表示方法不可被子类重写，但是可以重载 ；
- 修饰变量：表示变量一旦被赋值就不可以更改它的值；

### 1.1.8 什么是字节码？采用字节码的好处是什么？

- 什么是字节码： 
  - Java中引入了虚拟机的概念，即在机器和编译程序之间加入了一层抽象的虚拟的机器；
    - JVM在任何平台上都提供给编译程序一个的共同的接口；
    - 编译程序只需要面向JVM，生成JVM能够理解的代码，然后由解释器来将JVM代码转换为特定系统的机器码执行;
  - 在Java中，供JVM理解的代码叫做**字节码**（即扩展名为 .class的文 件），它不面向任何特定的处理器，只面向JVM。;
  - 每一种平台的解释器是不同的，但是实现的JVM是相同的；
    - Java源程序经过编译器编译后变成字节码，字节码由JVM解释执行；
    - JVM将每一条要执行的字节码送给解释器，解释器将其翻译成特定机器上的机器码，然后在特定的机器上运行；
    - 这也就是解释了Java的编译与解释并存的特点；
  -  Java源代码---->编译器---->JVM可执行的Java字节码(即虚拟指令)---->JVM---->JVM中解释器----->机 器可执行的二进制机器码---->程序运行。 
- 采用字节码的好处：
  - （高效）Java语言通过字节码的方式，在一定程度上解决了传统解释型语言执行效率低的问题，同时又保留了解释型语言可移植的特点;
  - （跨平台）由于字节码并不专对一种特定的机器，因此Java程序无须重新编译便可在多种不同的计算机上运行;

### 1.1.9 使用泛型的好处

泛型提供了编译时类型安全检测机制，该机制允许程序员在编译时检测到非法的类型。泛型的本质 是参数化类型，也就是说所操作的数据类型被指定为一个参数。比如我们要写一个排序方法，能够 对整型数组、字符串数组甚至其他任何类型的数组进行排序，我们就可以使用 Java 泛型。

<u>**泛型的好处**</u>：

以集合来举例，使用泛型的好处是我们**不必因为添加元素类型的不同而定义不同类型的集合**，如整型集合类，浮点型集合类，字符串集合类，我们可以定义一个集合来存放整型、浮点型，字符串型数据；只要把底层存储设置了Object即可，添加的数据全部都可向上转型为Object，此外还可以通过规则按照自己的想法控制存储的数据类型；

### 1.1.10 try-catch-finally异常处理模块的返回值问题

下面代码 的try-catch-finally语句，try⾥⾯有个return, finally⾥⾯也有个return，结果会返回什么？为什么

```java
public static int test1() {
    int a = 1;
    try {
        System.out.println(a / 0);
        a = 2;
    } catch (ArithmeticException e) {
        a = 3;
        return a;
    } finally {
        a = 4;
    }
    return a;
}

public static int test2() {
    int a = 1;
    try {
        System.out.println(a / 0);
        a = 2;
    } catch (ArithmeticException e) {
        a = 3;
        return a;
    } finally {
        a = 4;
        return a;
    }
}
```

- `test1()`返回3、`test2()`返回4；
- 理由：
  - 在执⾏try、catch中的return之前不管有没有出现异常，**⼀定会执⾏finally中的代码**（如果finally存在）；
  - 如果finally中有return语句，就会直接执⾏finally中的return⽅法，所以finally中的return语句 ⼀定会被执⾏的；
  - 执⾏流程：finally执⾏前的代码⾥⾯有包含return，则会先确定return返回值的（此时并没有返回运算后的值，而是先把要返回的值保存起来，不管finally中的代码怎么样，返回的值都不会改变，任然是之前保存的值），然后再执行finally的代码，最后再执⾏return；

### 1.1.11 Exception与Error包结构

Java可抛出(Throwable)的结构分为三种类型：被检查的异常(CheckedException)，运行时异常 (RuntimeException)，错误(Error)。

### 1.1.12 JAVA 异常分类

### 1.1.13 throw 和 throws 的区别

### 1.1.12 找出某目录下的所有子目录以及子文件并打印到控制台

```java
private static void getAllFilePaths(File filePath, List<String> paths) {
    File[] files = filePath.listFiles();
    if(files == null){
        return;
    }
    for(File f : files){
        if(f.isDirectory()){
            paths.add(f.getPath());
            getAllFilePaths(f,paths);
        }else{
            paths.add(f.getPath());
        }
    }
}
```

## 1.2 String字符串

### 1.2.1 String str = new String("aaa"); 创建了几个对象

可能是一个、也可能是两个：

- 创建⼀个对象：如果常量池中存在`aaa`，则直接new⼀个`aaa`的字符串对象； 
- 创建两个对象：常量池不存在对象`aaa`，则会在常量池创建⼀个`aaa`对象，同时也会在堆里面创建⼀个`aaa`对象；

### 1.2.2  下面代码是比较什么？输出结果是什么？为什么是这样的结果？

```java
String str1= new String("aaa"); 
String str2= "aaa"; 
String str3= "aaa";
System.out.println(str1 == str2);
System.out.println(str2 == str3);
```

- `==`⽐较两边的引⽤内存地址是否⼀样;
- 第一个比较返回false，因为new 创建新的对象会开辟新的空间，所以地址不⼀样；
- 第二个比较返回true，因为此时"aaa" 存在于常量池中，都是从常量池⾥⾯获取值，地址相等

### 1.2.3 写出下面代码的执行结果，如果需要两个都为true，应该怎么修改？

```java
String s1 = "aaa";
String s2 = s1 + ".bbb";
String s3 = "aaa" + ".bbb";
System.out.println(s2 == "aaa.bbb"); 
System.out.println(s3 == "aaa.bbb");
```

- 第⼀条打印语句的结果为false， `s2 = s1 + ".bbb"` 构建了⼀个新的String对象，并将对象引⽤赋予s2变量，常量池中的地址不⼀样，但是值⼀样的；
  - 变量 + 常量 = 来⾃堆；
- 第⼆条语句打印的结果为true，javac编译会对""**字符串常量**""直接相加的表达式进⾏优化，不⽤等到运⾏期再去进⾏加法运算处理，⽽是直接将其编译成⼀个这些常量相连的结果；
  - 常量 + 常量 = 来⾃常量池；
- 如果需要第⼀个输出为true，只需要把变量改为常量即可，例如： `fianl String s1 = "aaa";` 。

不管是new String("XXX")和直接常量赋值, 都会在字符串常量池创建对应的字符串常量，只不过new String("XXX")方式会在堆中创建⼀个对象去指向常量池的对象，普通的常量赋值是直接赋值给变量。

### 1.2.4 String、StringBuffer与StringBuilder的区别及使用场景

相同点：

- 三者都是final， 不允许被继承；
- 本质都是char[]字符数组实现；

区别：

- String、StringBuffer与StringBuilder中，String是**不可变**对象，另外两个是**可变**的；
- String每次操作都会产生新的String对象；
- StringBuilder 效率更快，因为它不需要加锁，不具备多线程安全；
- StringBuffer⾥⾯操作⽅法都会使用`synchronized`关键字加锁，所以效率相对较低，但是是线程安全的；

使⽤场景： 

  - 操作少量的数据⽤String，但是如果需要经常改变内容且操作数据多情况下最好不要⽤ String ， 因为每次⽣成中间对象性能会降低 ；
  - 单线程下操作⼤量的字符串⽤StringBuilder，虽然线程不安全但是不影响 ；
  - 多线程下操作⼤量的字符串，且需要保证线程安全使用StringBuffer；

## 1.3 OOP

### 1.3.1 什么是面向对象？

对比面向过程，是两种不同的处理问题的角度，面向过程更注重事情的每一个步骤及顺序，面向对象更注重事情有哪些参与者（对象）、及各自需要做什么；

### 1.3.1 面向对象的四大特性

- 抽象:
  - 关键词abstract声明的类叫作抽象类，abstract声明的⽅法叫抽象方法；
  - 如果⼀个类中包含了⼀个或多个抽象⽅法，这个类就必须指定成抽象类；
  - 抽象抽象属于⼀种特殊的方法，它只是一个方法声明，并没有⽅法体；
  - 实际应用：抽象⽀付  `pay(⾦额，订单号)`，默认实现是本地⽀付，微信⽀付，⽀付宝⽀付，银⾏卡⽀付  
- 封装：
  - 明确标识出允许外部使用的所有成员函数和数据项，对数据的访问只能通过对外暴露的已定义的接口，这样可以做到内部实现细节对外部调用隐蔽，外部调用无需修改或者关心内部实现；
  - 在java中通过关键字`private`，`protected`和`public`以及缺省的访问权限修饰符实现封装；
  - 封装可以让代码更容易理解和维护，也加强了代码的安全性；
- 继承：
  - ⼦类继承⽗类的特征（属性）和⾏为（方法），使得⼦类对象具有⽗类的⽅法和属性；
  - ⼦类可以在父类的基础上做出自己的改变、扩展，子类共性的方法或者属性直接使用父类的，而不需要自己再定义，只需扩展自己个性化的；
- 多态：
  - 同⼀个⾏为具有多个不同表现形式的能⼒，基于对象所属类的不同，外部对同一个方法的调用，实际执行的逻辑不同；
  - 可以通过继承，方法重写，父类引用指向子类对象来实现多态；

### 1.3.2 Overload和Override的区别

- 重载Overload：表示**同⼀个类**中可以有多个方法名相同的⽅法，但这些⽅法的参数列表各不相同（参参数类型、个数、顺序），方法返回值和访问修饰符可以不同；
- 重写Override：发生在父子类中，子类重写父类方法表示**子类**中的⽅法可以与**父类**中的某个⽅法的名称和参数完全相同；
  - 子类返回值范围、抛出的异常范围小于等于父类，访问修饰符范围大于等于父类；
  - 如果父类方法访问修饰符为private则子类就不能重写该方法；

### 1.3.3 接口和抽象类的区别

抽象类：

- 可以存在普通成员方法；
- 成员变量可以是各种类型的；
- 抽象类只能继承一个；
- 接口的设计目的是对类的行为进行**约束**（更准确的说是一种“有”约束，因为接口不能规定类不可以有什么行为），也就是提供一种机制，可以强制要求不同的类具有相同的行为；接口只约束了行为的有无，但不对如何实现行为进行限制；
- 接口是对行为的抽象，表达的是 like a 的关系，比如： Bird like a Aircraft （像飞行器一样可以 飞），但其本质上 is a Bird 。接口的核心是定义行为，即实现类可以做什么，至于实现类主体是 谁、是如何实现的，接口并不关心。

接口：

- 只能存在public abstract 方法；
- 成员变量只能是public static final类型的；
- 接口可以实现多个；
- 抽象类的设计目的是代码复用，当不同的类具有某些相同的行为（记为行为集合A），且其中一 部分行为的实现方式一致时，A的非真子集（记为B）可以让这些类都派生于一个抽象类。在这个抽象类中实现了B，避免让所有的子类来实现B，这就达到了代码复用的目的。而A-B的部分则留给各个子类自己实现。正是因为A-B在这里没有实现，所以抽象类不允许实例化出来（否则当调用 到A-B时，无法执行）；
- 抽象类是对类本质的抽象，表达的是 is a 的关系，比如： BMW is a Car，抽象类包含并实现子类的通用特性，将子类存在差异化的特性进行抽象，交由子类去实现

### 1.3.3 接口是否可以继承接口？接口是否支持多继承？类是否支持多继承？接口里面是否可以有方法实现？

- 接口中可以有静态⽅法和⽅法体；
- 接口中所有的⽅法必须是抽象⽅法（JDK8之后就不是）；
- 接⼝不是被类继承了，⽽是要被类实现；
- 接⼝⽀持多继承，类不⽀持多个类继；

⼀个类只能继承⼀个类，但是能实现多个接口，接口能继承另⼀个接口，接口的继承使⽤`extends`关键字，和类继承⼀样；

### 1.3.4 JDK8中接口新特性

- interface中可以有static⽅法，但必须有⽅法实现体，该⽅法只属于该接口，接口名直接调⽤该⽅法 ；
- 接口中新增`default`关键字修饰的⽅法，default⽅法只能定义在接口中，可以在子类或子接口中被重写，default定义的⽅法必须有⽅法体；
- ⽗接⼝的default⽅法如果在⼦接⼝或⼦类被重写，那么子接口的实现对象、⼦类对象，调⽤该⽅法，以重写为准；
- 本类、接⼝如果没有重写⽗类（即接⼝）的default⽅法，则在调⽤default⽅法时，使⽤⽗类 （接⼝） 定义的default⽅法逻辑；

## 1.4 集合框架

### 1.4.1 Vector、ArrayList和LinkedList的联系和区别及使用场景

- `ArrayList`：
  - 底层是**数组**实现，每个元素之间不能有间隔，需要一块连续的内存；
  - **线程不安全**；
  - 随机访问快（根据下标进行访问）；
  - 尾部的插入和删除性能可以，但是对其他部分进行插入或者删除元素时，需要对数组进行复制、移动、代价比高；
- `LinkedList`： 
  - 底层是**双向链表**实现，不需要连续内存；
  - **线程不安全**；
  - 随机访问慢（需要沿着链表进行遍历）；
  - 头、尾插入和删除性能高，向链表中间增删元素时，性能也比较低
  - *LinkedList还提供了 List 接口中没有定义的方法，专门用于操作表头和表尾元素，可以当作堆、栈、队列和双向队列使用;*

- `Vector`：底层是**数组**实现，**线程安全**的，操作的时候使⽤synchronized进⾏加锁;
  - *某一时刻只有一 个线程能够写 Vector，避免多线程同时写而引起的不一致性*；

使⽤场景：

- Vector已经很少⽤了；
- 增加和删除场景多则⽤LinkedList；
- 查询和修改多则⽤ArrayList；

### 1.4.2 保证ArrayList线程安全的方式

- ⽅式⼀：⾃⼰写个包装类，根据业务⼀般是`add/update/remove`加锁；
- ⽅式⼆：使用`Collections.synchronizedList(new ArrayList<>());` ，其使用使⽤synchronized加锁；
- ⽅式三：使用`CopyOnWriteArrayList<>()`，其使⽤`ReentrantLock`加锁；

### 1.4.3 CopyOnWriteArrayList和Collections.synchronizedList实现线程安全有什么区别及使用场景

- `CopyOnWriteArrayList`：
  - 在执行修改操作时，会拷⻉⼀份新的数组进⾏操作（例如add、set、 remove等)，这样的代价⼗分昂贵，在操作执行完毕后，会将原来集合指向新的集合；
  - 在源码中，使⽤`ReentrantLock`可重⼊锁来保证不会有多个线程同时拷⻉⼀份数组
  - 使用场景：由于读⾼性能，所以适⽤读操作远远⼤于写操作的场景中使⽤，因为读的时候是不需要加锁的， 直接获取，删除和增加是需要加锁的；==>读多写少 
- `Collections.synchronizedList`：
  - 线程安全的原因是因为它⼏乎在每个⽅法中都使⽤了`synchronized`同步锁；
  - 使用场景：与`CopyOnWriteArrayList`相反，写操作性能⽐`CopyOnWriteArrayList`好，读操作性能并不如 `CopyOnWriteArrayList`；==>写多读少

### 1.4.4 CopyOnWriteArrayList的设计思想及缺点

设计思想：**读写分离+最终⼀致**；

缺点：

- 内存占⽤问题，由于写时复制机制，在内存⾥会同时驻扎两个对象：旧的对象和新写⼊的对象；
- 如果对象⼤则容易发⽣**Yong GC**和**Full GC**；

### 1.4.5 ArrayList的扩容机制

<u>初始容量</u>：

- 如果未指定集合容量，调用无参的构造函数：
  - 在JDK1.7之前`ArrayList`的默认容量是10；
  - 在JDk1.7之后`ArrayList`的默认容量是1；
- 若已经指定容量，则集合大小为指定容量；

<u>扩容时机</u>：

- 以JDK1.8为例，当集合**第⼀次**添加元素的时候，集合大小扩容为10；
- 当`ArrayList`的元素个数⼤于其容量，按照`扩容的⼤⼩= 原始⼤⼩+原始⼤⼩/2`（上次容量的**1.5倍**）来进行扩容；

扩容源代码：

```java
    /**
     * Increases the capacity to ensure that it can hold at least the
     * number of elements specified by the minimum capacity argument.
     *
     * @param minCapacity the desired minimum capacity
     */
    private void grow(int minCapacity) {
        // overflow-conscious code
        int oldCapacity = elementData.length;
        int newCapacity = oldCapacity + (oldCapacity >> 1);
        if (newCapacity - minCapacity < 0)
            newCapacity = minCapacity;
        if (newCapacity - MAX_ARRAY_SIZE > 0)
            newCapacity = hugeCapacity(minCapacity);
        // minCapacity is usually close to size, so this is a win:
        elementData = Arrays.copyOf(elementData, newCapacity);
    }
```

### 1.4.6 设计⼀个简单的ArrayList

### 1.4.7 List和Set的区别

<u>List</u>：

- **有序**，按对象进入的顺序保存对象；
- **可重复**，允许多个Null元素对象；
- 遍历方式：
  - 可以使用`Iterator`取出所有元素，再逐一遍历；
  - 可以使用`get(int index)`获取指定下标的元素;

<u>Set</u>:

- **无序**;
- **不可重复**，且最多允许有一个Null元素对象；
- 遍历方式：
  - 只能用Iterator接口取得所有元素，再逐一遍历各个元素；

### 1.4.7 了解Map吗？用过哪些Map的实现

`HashMap`、`Hashtable`、`LinkedHashMap`、`TreeMap`、 `ConcurrentHashMap`；

### 1.4.8 HashMap和Hashtable的区别

<u>HashMap</u>：

- 底层是基于**数组+链表**;
- **非线程安全**的;
  - 虽然HashMap是线程不安全的，但是它的效率远远高于Hashtable，这样设计是合理的，因为大部分的使用场景都是单线程。当需要多线程操作的时候可以使用线程安全的 `ConcurrentHashMap`；
  - `ConcurrentHashMap`使用了分段锁，并不对整个数据进行锁定，效率比Hashtable高；
- 默认容量是**16** ，扩容因子是0.75，每次扩容大小为原来的 2的指数倍;
- **允许有空(null)的键和值**;
  - 为null的key只能有一个，因为必须保证key的唯一性；
  - 可以有多个key值对应的value为null；
- 对key的hashcode做了**二次散列**，从而避免key的分布不均匀问题，影响查询性能；

<u>Hashtable</u>：

- 基于**哈希表**实现；
- **线程安全**的(因为加了`synchronized`)；
- 默认容量是**11**，扩容因子是0.75，每次扩容大小为原来的 2n+1；
- **不允许有 null的健和值**；
- 直接使用key的hashcode对数组长度取模；

- Hashtable比HashMap多提供了`elments()` 和`contains()`两个方法:
  - `elments()`方法：继承自 Hashtable的父类Dictionnary，用于返回此Hashtable中的value的枚举。 
  - `contains()`方法：判断该Hashtable是否包含传入的value，作用与`containsValue()`一致；（事实上`contansValue()` 就只是调用了一下`contains()`方法）

### 1.4.9 对象的 hashCode()和equals()方法，及使用场景

hashCode方法和equals方法都是是顶级类`Object`中的⽅法：

- `hashCode()`方法的返回值类型是int，根据⼀定的hash规则对数据进行散列，散列后得到**散列值** ；
- `equals()`方法的返回值类型是boolean，一般会根据⾃定义的匹配规则，判断两个对象的内容是否一致；

使⽤场景：对象⽐较、集合容器⾥⾯排重、⽐较、排序；

### 1.4.10 两对象比较

- 如果两个对象相等，则hashcode值是相同的，并且对两个对象分别调用equals方法都返回true；
- 如果两个对象有相同的hashcode值，它们也不一定是相等的，如果重写equals方法后，则也同时必须重写hashCode()方法；
- hashCode()的默认行为是对堆上的对象产生独特值。如果一个类没有重写hashCode()方法，则该类的两个对象无论如何都不会相等（即使这两个对象指向相同的数据）；

### 1.4.11 HashMap中可以使用任何类作为 key 吗

可以但需要注意以下几点：

- 如果类重写了`equals()`方法，它也应该重写 `hashCode()` 方法；
- 类的所有实例需要遵循与 `equals()`方法和 `hashCode()` 方法相关的规则；
-  自定义的key类的最佳实践是使之为不可变的：
  - hashCode 值可以被缓存起来，拥有更好的性能；
  - 可以确保 hashCode 和 equals 在未来不会改变；

### 1.4.11 编写⼀个User对象，重写其中的hashCode()和equals()方法

### 1.4.12 HashMap和TreeMap的区别

### 1.4.13 Set和Map的关系

核⼼就是不保存重复的元素，存储⼀组唯⼀的对象；

- `Set`的每⼀种实现都是对应Map⾥⾯的⼀种封装
  - HashSet对应的就是HashMap;
  - TreeSet对应的就是TreeMap;

### 1.4.x HashSet与HashMap的区别

<u>HashSet</u>：

- 实现了Map接口；
- 以key-value的形式存储；
- 调用`put()`方法向map中添加元素；
- 使用key来计算hashCode；

<u>HashMap</u>：

- 实现了Set接口；
- 仅存储对象；
- 调用`add()`方法向set中添加元素；
- 使用对象来计算hashCode，如果两个对象的hashCode相同则继续调用`equals()`方法进行比较；

### 1.4.13 常见Map的排序规则是怎样的？

- `LinkedHashMap`按照添加顺序排序;
- `TreeMap`默认按照⾃然排序，如果需要⾃定义排序，使用`TreeMap(Comparetor c)`；

### 1.4.14 如果需要线程安全，且效率高的Map，应该怎么做？

多线程环境下可以⽤concurrent包下的`ConcurrentHashMap`, 或者使⽤` Collections.synchronizedMap()`对Map进行包装，`ConcurrentHashMap`不但是线程安全，并且他的效率⽐`Hashtable`要⾼很多；

### 1.4.15 为什么Collections.synchronizedMap后是线程安全的？

使⽤`Collections.synchronizedMap`对Map包装后返回的map是加锁的；

### 1.4.16 HashMap底层数据结构

`HashMap`底层是由**数组+链表+红⿊树**（JDK1.8之后有红⿊树）组成；

`HashMap`整体上是一个数组，然后数组中的元素是⼀个链表，即数组和链表的结合体：`Node<K, V>[] table`

- table是数组，数组的元素是Entry(Node继承Entry)；
- Entry元素是⼀个 key-value的键值对，它持有⼀个指向下个Entry的引⽤；
- table数组的每个Entry元素同时也作为当前 Entry链表的⾸节点，也指向了该链表的下个Entry元素；
- 在JDK1.8中，当链表Entry的⻓度⼤于8并且数组容量超过64，链表会转换成红⿊树

### 1.4.17 什么是Hash冲突及常见的解决办法

Hash冲突的意思是**不同key计算得到的Hash值相同**，需要放到同个bucket中；

常⻅的解决办法：

- 链表法（**HashMap采⽤的是链表法**）；
- 开放地址法；
- 再哈希法；

### 1.4.18 HashMap底层是 数组+链表+红黑树，为什么要用这几类结构呢？

- 数组`Node<K, V> table` ，根据对象的key的Hash值进⾏在数组⾥⾯是哪个节点；
- 链表的作⽤是解决Hash冲突，将Hash值⼀样的对象存在⼀个链表放在hash值对应的槽位；
- 红⿊树是JDK8引入用来替代超过8个节点的链表，主要是为了**提升查询性能**，从原来的O(n)提升到了 O(logn)；

### 1.4.19 HashMap底层为何要选择红黑树

⼆叉查找树在特殊情况下也会变成⼀条线性结构，和原先的链表存在⼀样的深度遍历问题，查找性能 就会慢， 使⽤红⿊树主要是提升查找数据的速度，红⿊树是平衡⼆叉树的⼀种，插⼊新数据后会通过左旋，右旋、变 ⾊等操作来保持平衡，解决单链表查询深度的问题 数据量少的时候操作数据，遍历线性表⽐红⿊树所消耗的资源少

### 1.4.20 HashMap为何要等到链表长度超过8才进行树化

* 红黑树是用来避免 DoS 攻击，防止链表超长时性能下降，树化应当是偶然情况，是保底策略；
* hash 表的查找，更新的时间复杂度是 `O(1)`，而红黑树的查找，更新的时间复杂度是 `O(log⁡n)`，并且`TreeNode` 占用空间也比普通 Node 的大，如非必要，尽量还是使用链表；
* hash 值如果足够随机，则在 hash 表内按泊松分布，在负载因子 0.75 的情况下，长度超过 8 的链表出现概率是 0.00000006（亿分之6），树化阈值选择 8 就是为了让树化几率足够小；

### 1.4.21 HashMap红黑树何时会退化成链表

<u>树化规则</u>

* 当链表长度超过树化阈值 8 时，先尝试扩容来减少链表长度，如果数组容量已经 >=64，才会进行树化

<u>退化规则</u>

* 情况1：在扩容时如果拆分树时，树元素个数 <= 6 则会退化链表
* 情况2：remove 树节点时，若 `root、root.left、root.right、root.left.left `有一个为 null ，也会退化为链表

### 1.4.20 HashMap的put流程

<u>put 流程</u>：

- HashMap 是懒惰创建数组的，首次使用才会创建数组；

- 通过一定的hash算法计算索引（桶下标）；

- 如果桶下标还没人占用，则创建 Node 占位返回；

- 如果桶下标已经有人占用：
  - 如果是`TreeNode`占用，则走红黑树的添加或更新逻辑；
  - 如果普通`Node`占用，则走链表的添加或更新逻辑，并且如果添加后链表长度超过树化阈值，走树化逻辑；

- 返回前会检查容量是否超过阈值，一旦超过进行扩容（加载因子0.75）；

<u>1.7 与 1.8 的区别</u>：

- 链表插入节点时，1.7 是头插法，1.8 是尾插法；

- 1.7 是大于等于阈值且没有空位时才扩容，而 1.8 是大于阈值就扩容；

- 1.8 在扩容计算 Node 索引时，会优化；

<u>扩容（加载）因子为何默认是 0.75f</u>：

- 在空间占用与查询时间之间取得较好的权衡；
- 大于这个值，空间节省了，但链表就会比较长影响性能；
- 小于这个值，冲突减少了，但扩容就会更频繁，空间占用也更多；

### 1.4.x HashMap的扩容机制

<u>1.7版本</u>

- 先⽣成新数组 
- 遍历⽼数组中的每个位置上的链表上的每个元素
- 取每个元素的key，并基于新数组⻓度，计算出每个元素在新数组中的下标 
- 将元素添加到新数组中去
- 所有元素转移完了之后，将新数组赋值给HashMap对象的table属性

<u>1.8版本</u> 

- 先⽣成新数组
- 遍历⽼数组中的每个位置上的链表或红⿊树 
  - 如果是链表，则直接将链表中的每个元素重新计算下标，并添加到新数组中去
  - 如果是红⿊树，则先遍历红⿊树，先计算出红⿊树中每个元素对应在新数组中的下标位置
    - 统计每个下标位置的元素个数
    - 如果该位置下的元素个数超过了8，则⽣成⼀个新的红⿊树，并将根节点的添加到新数组的对应位置
    - 如果该位置下的元素个数没有超过8，那么则⽣成⼀个链表，并将链表的头节点添加到新数组的 对应位置 
- 所有元素转移完了之后，将新数组赋值给HashMap对象的table属性

### 1.4.x HashMap 与 ConcurrentHashMap的区别

HashMap 与 ConcurrentHashMap 都是以key-value 形式的存储数据；

<u>HashMap</u>：

- Map接口的一个实现类，线程不安全；
- 底层数据结构：
  - JDK 1.8 之前：数组 + 链表；
  - JDK 1.8 之后：数组 + 链表 + 红黑树；（当链表中元素个数达到 8 的时候，为了提升查询效率，链表会转为红黑树）

<u>ConcurrentHashMap</u>：

-  JUC 下的类，线程安全；
- 底层数据结构：
  - JDK 1.8 之前：分段锁现实的 Segment + 数组+链表；
  - JDK 1.8 之后：采用 Node + CAS + Synchronized；

### 1.4.x Hashtable和ConcurrentHashMap的区别

* Hashtable 与 ConcurrentHashMap 都是线程安全的 Map 集合；
* Hashtable 并发度低，整个 Hashtable 对应一把锁，同一时刻只能有一个线程操作它；
* ConcurrentHashMap 并发度高；
  * JDK 1.8 之前ConcurrentHashMap 使用了Segment  + 数组+链表的结构，每个Segment 对应一把锁，如果多个线程访问不同的Segment，就不会冲突；
  * JDK 1.8 之后ConcurrentHashMap将数组的每个头节点作为锁，如果多个线程方法问的头节点不同，就不会冲突；

相比于HashTable类基本上所有的⽅法都是采⽤synchronized 进⾏线程安全控制，在⾼并发情况下效率低，ConcurrentHashMap则是采⽤了分段锁的思想提⾼性能，锁粒度更细化；

### 1.4.22 ConcurrentHashMap在JDK1.7和JDK1.8中的区别

<u>ConcurrentHashMap 1.7</u>

* 数据结构：`Segment(大数组) + HashEntry(小数组) + 链表`，每个 Segment 对应一把锁，如果多个线程访问不同的 Segment，则不会冲突；
* 并发度：Segment 数组大小即并发度，决定了同一时刻最多能有多少个线程并发访问；
  * **Segment 数组不能扩容**，意味着并发度在 ConcurrentHashMap 创建时就固定了；
* 索引计算
  * 假设大数组长度是2^m^，key 在大数组内的索引是 key 的二次 hash 值的高 m 位；
  * 假设小数组长度是2^n^，key 在小数组内的索引是 key 的二次 hash 值的低 n 位；
* 扩容：每个小数组的扩容相对独立，小数组在超过扩容因子时会触发扩容，每次扩容**翻倍**；
* Segment[0] 原型：首次创建其它小数组时，会以此原型为依据来创建（数组长度，扩容因子都会以原型为准）；

<u>ConcurrentHashMap 1.8</u>

* 数据结构：`Node 数组 + 链表或红黑树`，数组的每个头节点作为锁，如果多个线程访问的头节点不同，则不会冲突。首次生成头节点时如果发生竞争，利用 cas 而非 syncronized，进一步提升性能
* 并发度：Node 数组有多大，并发度就有多大，与 1.7 不同，Node 数组可以扩容
* 扩容：
  * 条件：Node 数组满 3/4 时就会扩容
  * 单位：以**链表**为单位从后向前迁移链表，迁移完成的将旧数组头节点替换为 ForwardingNode；
* 与 1.7 相比是懒惰初始化

### 1.4.x ConcurrentHashMap的capacity和factor

* capacity 代表预估的元素个数，capacity / factory 来计算出初始数组大小，需要贴近2^n^;
* loadFactor 只在计算初始数组大小时被使用，之后扩容固定为 3/4；
* 超过树化阈值时的扩容问题，如果容量已经是 64，直接树化，否则在原来容量基础上做 3 轮扩容

### 1.4.x ConcurrentHashMap扩容过程中的并发get和put

* 扩容时并发 get
  * 根据是否为 ForwardingNode 来决定是在新数组查找还是在旧数组查找，**不会阻塞**；
  * 如果链表长度超过 1，则需要对节点进行复制（创建新节点），以防止节点迁移后 next 指针改变；
  * 如果链表最后几个元素扩容后索引不变，则节点无需复制
* 扩容时并发 put
  * 如果 put 的线程与扩容线程操作的链表是同一个，put 线程会阻塞；
  * 如果 put 的线程操作的链表还未迁移完成，即头节点不是 ForwardingNode，则可以并发执行；
  * 如果 put 的线程操作的链表已经迁移完成，即头结点是 ForwardingNode，则可以协助扩容；

## 1.5 并发编程

### 1.5.1 进程、线程、协程之间的关系

### 1.5.2 协程对于多线程的优缺点

### 1.5.3 并发、并行、串行之间的区别

- <u>-串⾏</u>：⼀个任务执⾏完，才能执⾏下⼀个任务

- <u>并⾏(Parallelism)</u>：两个任务同时执⾏；

- <u>并发(Concurrency)</u>：两个任务整体看上去是同时执⾏，在底层，两个任务被拆成了很多份，然后 ⼀个⼀个执⾏，站在更⾼的⻆度看来两个任务是同时在执⾏的；

### 1.5.4 Java中实现多线程的方式

### 1.5.x 为什么要使用线程池

- **降低资源消耗**：提高线程利用率，降低创建和销毁线程的消耗；
- **提高响应速度**：任务来了，直接有线程可用可执行，而不是先创建线程，再执行；
- **提高线程的可管理性**：线程是稀缺资源，使用线程池可以统一分配调优监控；

### 1.5.x 常用的线程池有哪些

- newSingleThreadExecutor：创建一个单线程的线程池，此线程池保证所有任务的执行顺序按照任务的提交顺序执行；
- newFixedThreadPool：创建固定大小的线程池，每次提交一个任务就创建一个线程，直到线程达到线程池的最大大小；
- newCachedThreadPool：创建一个可缓存的线程池，此线程池不会对线程池大小做限制，线程池大小完全依赖于操作系统（或者说JVM）能够创建的最大线程大小；
- newScheduledThreadPool：创建一个大小无限的线程池，此线程池支持定时以及周期性执行任务的需求；

### 1.5.x 线程池参数

```java
public ThreadPoolExecutor(int corePoolSize,
                              int maximumPoolSize,
                              long keepAliveTime,
                              TimeUnit unit,
                              BlockingQueue<Runnable> workQueue,
                              ThreadFactory threadFactory,
                              RejectedExecutionHandler handler)
```



- <u>corePoolSize</u>：**核心线程数**，池中会**保留**的最多线程数，是正常情况下创建工作的线程数，这些线程创建后并不会消除，而是一种常驻线程；
- <u>maximumPoolSize</u>：**最大线程数**目，最大允许被**创建**的线程数（核心线程+救急线程的最大数目）；
- <u>keepAliveTime</u>：**空闲时间**，救急线程的空闲时间，如果在空闲时间内没有新任务，此线程资源会释放；
- 可以通过`setKeepAliveTime`方法来设置空闲时间；
- <u>unit</u>：**时间单位**，救急线程的生存时间单位，如秒、毫秒等；
- <u>workQueue</u>：工作队列，当没有空闲核心线程时，新来任务会加入到此队列排队，队列满会创建救急线程执行任务；
- <u>threadFactory</u>：线程工厂，用来生产线程执行任务，可以定制线程对象的创建，例如设置线程名字、是否是守护线程等；
- <u>handler</u>：拒绝策略，出发时机有两种情况；
  - 当所有线程都在繁忙，workQueue 也放满时，会触发拒绝策略；
  - 调用 shutdown 等方法关闭线程池；

### 1.5.x线程池的拒绝策略有哪些

- AbortPolicy：直接丢弃任务，抛出异常，这是默认策略；
- CallerRunsPolicy：只用调用者所在的线程来处理任务 ；
- DiscardOldestPolicy：丢弃等待队列中最旧的任务，并执行当前任务 ；
- DiscardPolicy：直接丢弃任务，也不抛出异常；

### 1.5.x 线程池处理流程

![image-20230325120522516](interview_notes.assets/image-20230325120522516.png)

线程池内部是通过队列+线程实现的，当我们利⽤线程池执⾏任务时：

- 如果此时线程池中的线程数量⼩于corePoolSize，即使线程池中的线程都处于空闲状态，也要创建新的线程来处理被添加的任务；
- 如果此时线程池中的线程数量等于corePoolSize，但是缓冲队列workQueue未满，那么任务被放入缓冲队列；
- 如果此时线程池中的线程数量⼤于等于corePoolSize，缓冲队列workQueue满，并且线程池中的数量⼩于maximumPoolSize，建新的线程来处理被添加的任务；
- 如果此时线程池中的线程数量⼤于corePoolSize，缓冲队列workQueue满，并且线程池中的数量等 于maximumPoolSize，那么通过 handler所指定的策略来处理此任务；
- 当线程池中的线程数量⼤于 corePoolSize时，如果某线程空闲时间超过keepAliveTime，线程将被 终⽌。这样，线程池可以动态的调整池中的线程数；

![image-20230322230139792](interview_notes.assets/image-20230322230139792.png)

### 1.5.x 线程池为什么是先添加列队而不是先创建最大线程

当线程池中的核⼼线程都在忙时，如果继续往线程池中添加任务，那么任务会先放⼊队列，队列满了之 后，才会新开线程。这就相当于，⼀个公司本来有10个程序员，本来这10个程序员能正常的处理各种需 求，但是随着公司的发展，需求在慢慢的增加，但是⼀开始这些需求只会增加在待开发列表中，然后这 10个程序员加班加点的从待开发列表中获取需求并进⾏处理，但是某⼀天待开发列表满了，公司发现现 有的10个程序员是真的处理不过来了，所以就开始新招员⼯了。

### 1.5.5 Java线程状态

<u>六种状态及转换</u>

![image-20230322225307573](interview_notes.assets/image-20230322225307573.png)

* 新建
  * 当一个线程对象被创建，但还未调用 start 方法时处于**新建**状态
  * 此时未与操作系统底层线程关联
* 可运行
  * 调用了 start 方法，就会由**新建**进入**可运行**
  * 此时与底层线程关联，由操作系统调度执行
* 终结
  * 线程内代码已经执行完毕，由**可运行**进入**终结**
  * 此时会取消与底层线程关联
* 阻塞
  * 当获取锁失败后，由**可运行**进入 Monitor 的阻塞队列**阻塞**，此时不占用 cpu 时间
  * 当持锁线程释放锁时，会按照一定规则唤醒阻塞队列中的**阻塞**线程，唤醒后的线程进入**可运行**状态
* 等待
  * 当获取锁成功后，但由于条件不满足，调用了 wait() 方法，此时从**可运行**状态释放锁进入 Monitor 等待集合**等待**，同样不占用 cpu 时间
  * 当其它持锁线程调用 notify() 或 notifyAll() 方法，会按照一定规则唤醒等待集合中的**等待**线程，恢复为**可运行**状态
* 有时限等待
  * 当获取锁成功后，但由于条件不满足，调用了 wait(long) 方法，此时从**可运行**状态释放锁进入 Monitor 等待集合进行**有时限等待**，同样不占用 cpu 时间
  * 当其它持锁线程调用 notify() 或 notifyAll() 方法，会按照一定规则唤醒等待集合中的**有时限等待**线程，恢复为**可运行**状态，并重新去竞争锁
  * 如果等待超时，也会从**有时限等待**状态恢复为**可运行**状态，并重新去竞争锁
  * 还有一种情况是调用 sleep(long) 方法也会从**可运行**状态进入**有时限等待**状态，但与 Monitor 无关，不需要主动唤醒，超时时间到自然恢复为**可运行**状态

> ***其它情况（只需了解）***
>
> * 可以用 interrupt() 方法打断**等待**、**有时限等待**的线程，让它们恢复为**可运行**状态
> * park，unpark 等方法也可以让线程等待和唤醒

<u>五种状态</u>

五种状态的说法来自于操作系统层面的划分

![image-20230322225413465](interview_notes.assets/image-20230322225413465.png)

* 运行态：分到 cpu 时间，能真正执行线程内代码的
* 就绪态：有资格分到 cpu 时间，但还未轮到它的
* 阻塞态：没资格分到 cpu 时间的
  * 涵盖了 java 状态中提到的**阻塞**、**等待**、**有时限等待**
  * 多出了阻塞 I/O，指线程在调用阻塞 I/O 时，实际活由 I/O 设备完成，此时线程无事可做，只能干等
* 新建与终结态：与 java 中同名状态类似，不再啰嗦

### 1.5.6 多线程开发中的常用方法

### 1.5.8 多线程的业务场景

### 1.5.9 不是线程安全的数据结构

### 1.5.x 守护线程的理解

线程分为⽤户线程和守护线程

- ⽤户线程就是普通线程；
- 守护线程就是JVM的后台线程，⽐如垃圾回收线程就是⼀个守护线程，守护线程会在其他普通线程都停⽌运⾏之后⾃动关闭。我们可以通过设置 thread.setDaemon(true)来把⼀个线程设置为守护线程；

### 1.5.10 线程安全的理解

当多个线程访问一个对象时，如果不用进行额外的同步控制或其他的协调操作，调用这个对象的行为都可以获得正确的结果，我们就说这个对象是线程安全的；

线程安全要考虑三个方面：可见性、有序性、原子性

- 可见性：一个线程对共享变量修改，另一个线程能看到最新的结果；

- 有序性：一个线程内代码按编写顺序执行；

- 原子性：一个线程内多行代码以一个整体运行，期间不能有其它线程的代码插队；

### 1.5.11 volatile能否保证线程安全

<u>原子性</u>

* 起因：多线程下，不同线程的**指令发生了交错**导致的共享变量的读写混乱；
* 解决：用悲观锁或乐观锁解决，volatile 并不能解决原子性；

<u>可见性</u>

* 起因：由于**编译器优化、或缓存优化、或 CPU 指令重排序优化**导致的对共享变量所做的修改另外的线程看不到；
* 解决：用 volatile 修饰共享变量，能够防止编译器等优化发生，让一个线程对共享变量的修改对另一个线程可见；

<u>有序性</u>

* 起因：由于**编译器优化、或缓存优化、或 CPU 指令重排序优化**导致指令的实际执行顺序与编写顺序不一致；
* 解决：用 volatile 修饰共享变量会在读、写共享变量时加入不同的屏障，阻止其他读写操作越过屏障，从而达到阻止重排序的效果；
* 注意：
  * **volatile 变量写**加的屏障是阻止上方其它写操作越过屏障排到 **volatile 变量写**之下；
  * **volatile 变量读**加的屏障是阻止下方其它读操作越过屏障排到 **volatile 变量读**之上；
  * volatile 读写加入的屏障只能防止同一线程内的指令重排；

### 1.5.x wait和sleep的区别

<u>共同点</u>

* wait() ，wait(long) 和 sleep(long) 的效果都是让当前线程暂时放弃 CPU 的使用权，进入**阻塞状态**；

<u>不同点</u>

* 方法归属不同
  * sleep(long) 是 Thread 的静态方法；
  * 而 wait()，wait(long) 都是 Object 的成员方法，每个对象都有；

* 醒来时机不同
  * 执行 sleep(long) 和 wait(long) 的线程都会在等待相应毫秒后醒来；
  * wait(long) 和 wait() 还可以被 notify 唤醒，wait() 如果不唤醒就一直等下去；
  * 它们都可以被打断（interrupt）唤醒；

* 锁特性不同（重点）
  * wait 方法的调用必须先获取 wait 对象的锁，而 sleep 则无此限制；
  * wait 方法执行后会释放对象锁，允许其它线程获得该对象锁（我放弃 cpu，但你们还可以用）；
  * 而 sleep 如果在 synchronized 代码块中执行，并不会释放对象锁（我放弃 cpu，你们也用不了）；

### 1.5.x lock vs synchronized的区别

* 语法层面
  * synchronized 是关键字，源码在 jvm 中，用 c++ 语言实现；
  * Lock 是接口，源码由 jdk 提供，用 Java 语言实现；
  * 使用 synchronized 时，退出同步代码块锁会自动释放，而使用 Lock 时，需要手动调用 unlock 方法释放锁；
* 功能层面
  * 二者均属于悲观锁、都具备基本的互斥、同步、锁重入功能；
  * Lock 提供了许多 synchronized 不具备的功能，例如获取等待状态、公平锁、可打断、可超时、多条件变量
  * Lock 有适合不同场景的实现，如 ReentrantLock， ReentrantReadWriteLock
* 性能层面
  * 在没有竞争时，synchronized 做了很多优化，如偏向锁、轻量级锁，性能不赖；
  * 在竞争激烈时，Lock 的实现通常会提供更好的性能；

**公平锁**

* 公平锁的公平体现
  * **已经处在阻塞队列**中的线程（不考虑超时）始终都是公平的，先进先出
  * 公平锁是指**未处于阻塞队列**中的线程来争抢锁，如果队列不为空，则老实到队尾等待
  * 非公平锁是指**未处于阻塞队列**中的线程来争抢锁，与队列头唤醒的线程去竞争，谁抢到算谁的
* 公平锁会降低吞吐量，一般不用

**条件变量（Condition类）**

* ReentrantLock 中的条件变量功能类似于普通 synchronized 的 wait，notify，用在当线程获得锁后，发现条件不满足时，临时等待的链表结构
* 与 synchronized 的等待集合不同之处在于，ReentrantLock 中的条件变量可以有多个，可以实现更精细的等待、唤醒控制

### 1.5.x ThreadLocal的理解

ThreadLocal是Java中所提供的线程本地存储机制，可以利⽤该机制将**数据缓存在某个线程内部**， 该线程可以在任意时刻、任意⽅法中获取缓存的数据；

<u>作用</u>

* ThreadLocal 可以实现**资源对象**的**线程间隔离**，让每个线程各用各的资源对象，避免争用引发的线程安全问题；
* ThreadLocal 同时实现了**线程内的资源共享**；

<u>原理</u>

每个线程（Thread对象）内有一个 **ThreadLocalMap** 类型的成员变量，用来存储资源对象，Map的key为ThreadLocal对象，Map的value为需要缓存的值

* 调用 set 方法，就是以 **ThreadLocal 自己作为 key**，资源对象作为 **value**，放入当前线程的 ThreadLocalMap 集合中；
* 调用 get 方法，就是以 **ThreadLocal 自己作为 key**，到当前线程中查找关联的资源值；
* 调用 remove 方法，就是以 **ThreadLocal 自己作为 key**，移除当前线程关联的资源值；

所以ThreadLocal只起到关联的作用，真正起到线程隔离作用的是ThreadLocalMap；

ThreadLocalMap 的一些特点

* key 的 hash 值统一分配；
* 初始容量 16，扩容因子 2/3，扩容容量翻倍；
* key 索引冲突后用**开放寻址法**解决冲突；

### 1.5.x ThreadLocal的key为什么被设计为弱引用

Thread 可能需要长时间运行（如线程池中的线程），如果 key 不再使用，需要在内存不足（GC）时释放其占用的内存，设计为弱引用方便GC回收key对象；

### 1.5.x ThreadLocal内存释放时机

* 被动 GC 释放 key
  * 仅是让 key 的内存释放，**关联 value 的内存并不会释放**；
* 懒惰被动释放 value
  * get key 时，发现是 null key，则释放其 value 内存；
  * set key 时，会使用**启发式扫描**，清除临近的 null key 的 value 内存，启发次数与元素个数，是否发现 null key 有关；
* 主动 remove 释放 key，value
  * 会同时释放 key，value 的内存，也会清除临近的 null key 的 value 内存；
  * 推荐使用它，因为一般使用 ThreadLocal 时都把它作为静态变量（即强引用），因此无法被动依靠 GC 回收；

### 1.5.12 为什么会出现脏读

### 1.5.13 什么是指令重排

### 1.5.14 什么是happens-before

### 1.5.15 并发编程三要素+举例

### 1.5.16 进程间的调度算法

### 1.5.17 线程间的调度算法

### 1.5.18 Java中的锁

### 1.5.x 悲观锁和乐观锁的区别

* 悲观锁的代表是 synchronized 和 Lock 锁
  * 核心思想：**线程只有占有了锁，才能去操作共享变量，每次只有一个线程占锁成功，获取锁失败的线程，都得停下来等待**；
  * 线程从运行到阻塞、再从阻塞到唤醒，涉及线程上下文切换，如果频繁发生，影响性能；
  * 实际上，线程在获取 synchronized 和 Lock 锁时，如果锁已被占用，都会做几次重试操作，减少阻塞的机会；

* 乐观锁的代表是 AtomicInteger，使用 cas 来保证**原子性**
  * 其核心思想：**无需加锁，每次只有一个线程能成功修改共享变量，其它失败的线程不需要停止，不断重试直至成功**；
  * 由于线程一直运行，不需要阻塞，因此不涉及线程上下文切换；
  * 它需要多核 cpu 支持，且线程数不应超过 cpu 核数；

### 1.5.19 多线程死锁的例子

### 1.5.20 死锁的4个必要条件

- ⼀个资源每次只能被⼀个线程使⽤；
- ⼀个线程在阻塞等待某个资源时，不释放已占有资源；
- ⼀个线程已经获得的资源，在未使⽤完之前，不能被强⾏剥夺；
- 若⼲线程形成头尾相接的循环等待资源关系；

### 1.5.21 优化代码，解决死锁

### 1.5.22 设计⼀个简单的不可重入锁

### 1.5.23 设计⼀个简单的可重入锁

### 1.5.24 对synchronized的理解

## 1.6 JVM

### 1.6.x JVM 内存结构

![image-20230325152808172](interview_notes.assets/image-20230325152808172.png)

- <u>程序计数器</u>
  - 一块较小的内存空间，是当前线程所执行的字节码的**行号**指示器；
    - 若当前方法是 Java 方法，程序计数器的值是虚拟机字节码指令的地址（当前指令的地址）；
    - 若当前方法是native方法，程序计数器的值是 undefined；
- <u>虚拟机栈</u>
  - 描述**Java方法**执行的内存模型，每个方法在执行的同时都会创建一个栈帧（Stack Frame）用于存储局部变量表、操作数栈、动态链接、方法出口等信息;
  - 每一个方法从调用直至执行完成的过程，就对应着一个栈帧在虚拟机栈中入栈到出栈的过程;
- <u>本地方法栈</u>
  - 本地方法栈和虚拟机栈作用类似，区别是虚拟机栈为执行 Java 方法服务，而本地方法栈则为 **Native 方法**服务；
  - HotSpot VM 直接就把本地方法栈和虚拟机栈合二为一；
- <u>堆</u>
  - 运行时数据区，Java 虚拟机中内存最大的一块，几乎所有的**对象实例**都在这里分配内存；
  - 是垃圾收集器进行垃圾收集的最重要的内存区域；
  - 由于现代 VM 采用分代收集算法，因此 Java 堆从 GC 的角度还可以细分为
    - 新生代(Eden 区、From Survivor 区和 To Survivor 区)；
    - 老年代；
- <u>方法区</u>
  - 也称非堆，用于存储已被虚拟机加载的**类**信息、**常量、静态变量、即时编译后的代码**等数据；
  - 运行时常量池：是方法区的一部分，存常量（比如static final修饰的，比如String 一个字符串）和符号引用；

### 1.6.x JVM中线程私有与线程共享区域

- <u>线程私有区域</u>：程序计数器、虚拟机栈、本地方法栈；

- <u>线程共享区域</u>：JAVA 堆、方法区；

此外还有直接内存；

线程私有数据区域生命周期与线程相同, 依赖用户线程的启动/结束而创建/销毁（在 Hotspot  VM内, 每个线程都与操作系统的本地线程直接映射，因此这部分内存区域的存/否跟随本地线程的生/死对应）；

线程共享区域随虚拟机的启动/关闭而创建；

### 1.6.x JVM中会发生内存溢出的区域

* 不会出现内存溢出的区域：程序计数器；
* 出现 OutOfMemoryError 的情况
  * **堆**内存耗尽：对象越来越多，又一直在使用，不能被垃圾回收；
  * **方法区**内存耗尽 ：加载的类越来越多，很多框架都会在运行期间动态产生新的类；
  * **虚拟机栈**累积：每个线程最多会占用 1 M 内存，线程个数越来越多，而又长时间运行不销毁时；
* 出现 StackOverflowError 的区域
  * JVM **虚拟机栈<u>内部</u>**、**本地方法栈<u>内部</u>**：原因有方法递归调用未正确结束、反序列化 json 时循环引用；（线程内）

### 1.6.x 方法区、永久代、元空间的关系

* **方法区**是 JVM 规范中定义的一块内存区域，用来存储类元数据、方法字节码、即时编译器需要的信息等；
* **永久代**是 Hotspot 虚拟机对 JVM 规范的实现（1.8 之前），使用**Java堆**的来实现方法区；
* **元空间**是 Hotspot 虚拟机对 JVM 规范的另一种实现（1.8 以后），使用**本地内存**作为这些信息的存储空间；

<u>类数据何时被放入到元空间</u>：

![image-20230325160835605](interview_notes.assets/image-20230325160835605.png)

* 当第一次用到某个类是，由**类加载器**将 class 文件的类元信息读入，并存储于元空间；
* X，Y 的类元信息是存储于元空间中，无法直接访问；
* 可以用 X.class，Y.class 间接访问类元信息，它们俩属于 java 对象，我们的代码中可以使用；

<u>元空间中的数据何时被清理</u>：

![image-20230325160925881](interview_notes.assets/image-20230325160925881.png)

* 堆内存中：当一个**类加载器对象**，这个类加载器对象加载的所有**类对象**，这些类对象对应的所有**实例对象**都没人引用时，GC 时就会对它们占用的对内存进行释放
* 元空间中：内存释放**以类加载器为单位**，当堆中类加载器内存释放时，对应的元空间中的类元信息也会释放

### 1.6.x Java代码的执行的执行流程

* 执行 javac 命令
  * 编译源代码为字节码；
* 执行 java 命令
  - 创建 JVM，调用类加载子系统加载 class，将类的信息存入**方法区**；
  - 创建 main 线程，使用的内存区域是 **JVM 虚拟机栈**，开始执行 main 方法代码；
  - 如果遇到了未见过的类，会继续触发类加载过程，同样会存入**方法区**；
  - 需要创建对象，会使用**堆**内存来存储对象；
  - 不再使用的对象，会由**垃圾回收器**在内存不足时回收其内存；
  - 调用方法时，
    - 方法内的局部变量、方法参数所使用的是  **JVM 虚拟机栈**中的栈帧内存；
    - 先要到**方法区**获得到该方法的字节码指令，由**解释器**将字节码指令解释为机器码执行；
    - 会将要执行的指令行号读到**程序计数器**，这样当发生了线程切换，恢复时就可以从中断的位置继续；
  - 对于非 java 实现的方法调用，使用内存称为**本地方法栈**（对于 Oracle 的 Hotspot 虚拟机实现，不区分虚拟机栈和本地方法栈）
  - 对于热点方法调用，或者频繁的循环代码，由 **JIT 即时编译器**将这些代码编译成机器码缓存，提高执行性能；

### 1.6.x 什么是STW

STW: Stop-The-World，是在垃圾回收算法执⾏过程当中，需要将JVM**内存冻结**的⼀种状态。

在STW 状态下，JAVA的所有线程都是停⽌执⾏的（GC线程除外），native⽅法可以执⾏，但是不能与JVM交 互。

GC各种算法优化的重点，就是减少STW，同时这也是JVM调优的重点。

### 1.6.x JVM内存参数

JVM参数⼤致可以分为三类：

- 标准指令： -开头，这些是所有的HotSpot都⽀持的参数。可以⽤java -help 打印出来；
- ⾮标准指令： -X开头，这些指令通常是跟特定的HotSpot版本对应的。可以⽤java -X 打印出来；
- 不稳定参数： -XX 开头，这⼀类参数是跟特定HotSpot版本对应的，并且变化⾮常⼤。

<u>堆内存，按大小设置</u>

![image-20230325161802095](interview_notes.assets/image-20230325161802095.png)

* -Xms：最小堆内存（包括新生代和老年代）；
* -Xmx：最大堆内存（包括新生代和老年代）；

通常建议将 -Xms 与 -Xmx 设置为大小相等，即不需要保留内存，不需要从小到大增长，这样性能较好；

* -XX:NewSize 与 -XX:MaxNewSize：设置新生代的最小与最大值，但一般不建议设置，由 JVM 自己控制；
* -Xmn：设置新生代大小，相当于同时设置了 -XX:NewSize 与 -XX:MaxNewSize 并且取值相等；

<u>堆内存，按比例设置</u>

![image-20230325162050636](interview_notes.assets/image-20230325162050636.png)

* -XX:NewRatio=2:1 表示老年代占两份，新生代占一份
* -XX:SurvivorRatio=4:1 表示新生代分成六份，伊甸园占四份，from 和 to 各占一份

<u>元空间内存设置</u>

- 

<u>代码缓存内存设置</u>

<u>线程内存设置</u>

### 1.6.x JVM确定回收对象算法

<u>引用计数法</u>

- 一个对象如果没有任何与之关联的引用，即他的引用计数为 0，则说明对象不太可能再被用到，那么这个 对象就是可回收对象；

<u>可达性分析</u>；

- 通过一系列的GC Root 对象，即那些一定不会被回收的对象作为起点搜索。如果在GC roots和一个对象之间没有可达路径，则称该对象是不可达的；
- 不可达对象不等价于可回收对象，不可达对象变为可回收对象至少要经过两次标记过程。两次标记后仍然是可回收对象，则将面临回收；

### 1.6.x JVM GC的理解

- 垃圾回收，GC能帮助我们释放JVM内存（回收区域是**堆内存**，不包括虚拟机栈；），可以一定程度避免OOM问题，但是也无法完全避免；
- GC 的目的在于实现无用对象内存自动释放，减少内存碎片、加快分配速度；

- Java的GC是自动工作的，不像C++需要主动调用；
- 当new对象的时候，GC就开始监控这个对 象的地址大小和使用情况了，通过可达性分析算法寻找不可达的对象然后进行标记看看是否需要 GC回收掉释放内 存；

### 1.6.x 可以保证GC执行吗

不能，我只能通过手动执行` System.gc() `方法通知GC执行，但是他是否执行的未知的；

### 1.6.x JVM垃圾回收算法

<u>标记清除法</u>

![image-20230325162418363](interview_notes.assets/image-20230325162418363.png)

1. 找到 GC Root 对象，即那些一定不会被回收的对象，如正执行方法内局部变量引用的对象、静态变量引用的对象；
2. 标记阶段：沿着 GC Root 对象的引用链找，直接或间接引用到的对象加上标记；
3. 清除阶段：释放未加标记的对象占用的内存；

特点：

* 标记速度与存活对象线性关系；
* 清除速度与内存大小线性关系；
* 缺点是**会产生内存碎片**；

<u>标记整理法</u>

![image-20230325162444165](interview_notes.assets/image-20230325162444165.png)

1. 前面的标记阶段、清理阶段与标记清除法类似；
2. 多了一步整理的动作，将存活对象向一端移动，可以避免内存碎片产生；

特点：

* 标记速度与存活对象线性关系；

* 清除与整理速度与内存大小成线性关系；
* 缺点是**性能上较慢**；

<u>标记复制法</u>

![image-20230325162509497](interview_notes.assets/image-20230325162509497.png)

1. 将整个内存分成两个大小相等的区域，from 和 to，其中 to 总是处于空闲，from 存储新创建的对象；
2. 标记阶段与前面的算法类似；
3. 在找出存活对象后，会将它们从 from 复制到 to 区域，复制的过程中自然完成了碎片整理；
4. 复制完成后，交换 from 和 to 的位置即可；

特点：

* 标记与复制速度与存活对象成线性关系
* 缺点是**会占用成倍的空间**

### 1.6.x JVM GC分代回收思想

理论依据是大部分对象朝生夕灭，用完立刻就可以回收，另有少部分对象会长时间存活，每次很难回收，根据这两类对象的特性将回收区域分为**新生代**和**老年代**，新生代采用标记复制法、老年代一般采用标记整理法；

- 新生代 young
  - 伊甸园 eden，最初分配对象的场所；
  - 幸存区 survivor，当伊甸园内存不足，会发生Minor GC，GC后的幸存对象存放在这里，分成 from 和 to，采用标记复制算法；
    - 当伊甸园内存不足，标记伊甸园与 from的存活对象；
    - 将存活对象采用复制算法复制到 to 中，复制完毕后，伊甸园和 from 内存都得到释放；
    - 将 from 和 to 交换位置；
- 老年代 old：当幸存区对象熬过几次回收（最多15次），晋升到老年代（幸存区内存不足或大对象会导致提前晋升）
  - 老年代当空间占用到达某个值之后就会触发Full GC，一般使用标记整理的执行算法；

### 1.6.x GC 规模

* Minor GC：发生在新生代的垃圾回收，暂停时间短；
* Mixed GC：新生代 + 老年代部分区域的垃圾回收，G1 收集器特有；
* Full GC：新生代 + 老年代完整垃圾回收，暂停时间长，**应尽力避免**；

### 1.6.x Minor GC与Full GC的发生时机

- 新生代内存（Eden区）不够用时候发生Minor GC，也叫YGC；
- Full GC发生情况：
  - 老年代被写满；
  - 持久代被写满；
  - System.gc()被显示调用（只是会告诉需要GC，但什么时候发生并不知道）；

### 1.6.x 常见的垃圾回收器

<u>垃圾回收器 - Parallel GC</u>

* eden 内存不足发生 Minor GC，采用标记复制算法，需要暂停用户线程；
* old 内存不足发生 Full GC，采用标记整理算法，需要暂停用户线程；

* 会启用多个线程来并行回收，**注重吞吐量**；

<u>垃圾回收器 - ConcurrentMarkSweep GC（CMS）</u>

* 它是工作在 old 老年代，支持**并发标记**的一款回收器，采用**并发清除**算法；
  * 并发标记时不需暂停用户线程；
  * 重新标记时仍需暂停用户线程；

* 如果并发失败（即回收速度赶不上创建新对象速度），会触发 Full GC；

* **注重响应时间**；

<u>垃圾回收器 - G1 GC</u>

* **响应时间与吞吐量兼顾**
* 把整个堆划分为多个大小相等的 独立区域（Region），每个区域都可以充当 eden，survivor，old， humongous，其中 humongous 专为大对象准备；
* 阶段：
  * 新生代回收：eden 内存不足，标记复制 STW；
  * 并发标记：
    * 当老年代占用内存超过阈值后，触发并发标记，这时无需暂停用户线程；
    * 并发标记之后，会有重新标记阶段解决漏标问题，此时需要暂停用户线程；
  * 混合收集：
    * 并发标记完成后就知道了老年代有哪些存活对象，随后进入混合收集阶段；
    * 不会对所有老年代区域进行回收，而是根据**暂停时间目标**优先回收价值高（存活对象少）的区域（这也是 Gabage First 名称的由来）
    * 参与复制的有 eden、survivor、old，其中 old 会根据**暂停时间目标**，选择部分回收价值高的区域，复制时 STW
* 如果并发失败（即回收速度赶不上创建新对象速度），会触发 Full GC；

### 1.6.x JVM类加载过程

<u>加载</u>

将类的.class文件中的二进制数据读入到内存中，将其放在运行时数据区的**方法区**内，然后创建一个**类.class** 对象用来封装类在方法区内的数据结构作为这个类的各种数据的访问入口；

- 如果此类的父类没有加载，先加载父类；
- 加载是懒惰执行；

<u>链接</u>

- 验证：主要是为了确验证类是否符JVM规范，并作合法性和安全性检查；

- 准备：为 static 变量分配空间，设置**默认值**；（注意：如果给static变量设置了赋值语句，此时并不会执行，而是要到初始化阶段才会执行赋值语句）
- 解析：将常量池的符号引用解析为直接引用；

<u>初始化</u>

- 静态代码块、static 修饰的变量赋值、static final 修饰的引用类型变量赋值，会被合并成一个 `<cinit>` 方法，在初始化时被调用；
- static final 修饰的基本类型变量赋值，在链接阶段就已完成；
- 初始化是懒惰执行；

### 1.6.x JDK8的类加载器

| **名称**                | **加载哪的类**        | **说明**                       |
| ----------------------- | --------------------- | ------------------------------ |
| Bootstrap ClassLoader   | JAVA_HOME/jre/lib     | 无法直接访问                   |
| Extension ClassLoader   | JAVA_HOME/jre/lib/ext | 上级为 Bootstrap，显示为  null |
| Application ClassLoader | classpath             | 上级为 Extension               |
| 自定义类加载器          | 自定义                | 上级为 Application             |

- <u>启动类加载器（Bootstrap ClassLoader）</u>
  - 最顶层类加载器，他的父类加载器是个null，也就是没有父类加载器；
  - 负责加载jvm的核心类库， 比如`java.lang.*`等，从系统属性中的**sun.boot.class.path** 所指定的目录中加载类库；
  - 他的具体实现由Java虚拟机底层C++代码实现；
- <u>扩展类加载器（Extension ClassLoader）</u>
  - 父类加载器是Bootstrap ClassLoader;
  - 从 **java.ext.dirs** 系统属性所指定的目录中加载类库，或者 从JDK的安装目录的 **jre/lib/ext 子目录**（扩展目录）下加载类库，如果把用户的jar文件放在这个目 录下，也会自动由扩展类加载器加载;
  - 继承自 java.lang.ClassLoader ;
- <u>应用程序类加载器（Application ClassLoader）</u>
  - 父类加载器是Extension ClassLoader;
  - 从环境变量classpath或者系统属性 **java.class.path** 所指 定的目录中加载类;
  - 继承自 java.lang.ClassLoader ;
- <u>自定义类加载器（User ClassLoader）</u>
  - 除了上面三个自带的以外，用户还能制定自己的类加载器;
  - 所有自定义的类加载器都应该继承 自 java.lang.ClassLoader 。比如热部署、tomcat都会用到自定义类加载器;

### 1.6.x 什么是双亲委派机制

如果一个类加载器收到了类加载的请求：

- 首先会从自己缓存里查找是否之前加载过这个class
  -  加载过则直接返回
  - 没加载过的话他不会自己亲自去加载，他会把这个请求委派给**父类加载器**去完成
- 每一层都是如此，类似递归，一直递归到顶层父类，也就是 Bootstrap ClassLoader ，只要加载完成就会返回结果；
- 如果顶层父类加载器无法加载此class，则会返回去交给子类加载器去尝试加载；
- 若最底层的子类加载器也没找到，则会抛出 ClassNotFoundException 

### 1.6.x 双亲委派的意义

- 让上级类加载器中的类对下级共享（反之不行），即能**让自定义类能依赖到 jdk 提供的核心类**；

- 让类的加载有优先次序，**保证核心类优先加载**；
- 防止内存中出现多份同样的字节码，安全；

### 1.6.x JDBC为什么要破坏双亲委派模型

### 1.6.x Tomcat为什么要破坏双亲委派模型

### 1.6.x 如何破坏双亲委派模型

重写 loadClass 方法，因为 loadClass 是核心入口，将其重写成自定义逻 辑即可破坏双亲委派模型。

### 1.6.x 对象的引用类型分成哪几类

<u>强引用</u>

- 普通变量赋值即为强引用，如 `A a = new A();`；

- 通过 GC Root 的引用链，**如果强引用不到该对象，该对象才能被回收**；

![image-20230325220126879](interview_notes.assets/image-20230325220126879.png)

<u>软引用（SoftReference）</u>

- 例如：`SoftReference a = new SoftReference(new A());`

- 如果仅有软引用该对象时，**首次垃圾回收不会回收该对象，如果内存仍不足，再次回收时才会释放对象**

- 软引用自身需要配合引用队列来释放

- 典型例子是反射数据

![image-20230325220148138](interview_notes.assets/image-20230325220148138.png)

<u>弱引用（WeakReference）</u>

- 例如：`WeakReference a = new WeakReference(new A());`

- 如果仅有弱引用引用该对象时，**只要发生垃圾回收，就会释放该对象**

- 弱引用自身需要配合引用队列来释放

- 典型例子是 ThreadLocalMap 中的 Entry 对象

![image-20230325220159195](interview_notes.assets/image-20230325220159195.png)

<u>虚引用（PhantomReference）</u>

- 例如：`PhantomReference a = new PhantomReference(new A(), referenceQueue);`

- 必须配合引用队列一起使用，当虚引用所引用的对象被回收时，由 Reference Handler 线程将虚引用对象入队，这样就可以知道哪些对象被回收，从而对它们关联的资源做进一步处理

- 典型例子是 Cleaner 释放 DirectByteBuffer 关联的直接内存

![image-20230325220208550](interview_notes.assets/image-20230325220208550.png)

### 1.6.x finalize 原理

finalize 是 Object 中的一个方法，如果子类重写它，垃圾回收时此方法会被调用，可以在其中进行资源释放和清理工作；但是将资源释放和清理放在 finalize 方法中非常不好，非常影响性能，严重时甚至会引起 OOM，**从 Java9 开始就被标注为 @Deprecated，不建议被使用了**；

### 1.6.x finalize 缺点

* 无法保证资源释放：FinalizerThread 是守护线程，代码很有可能没来得及执行完，线程就结束了
* 无法判断是否发生错误：执行 finalize 方法时，会吞掉任意异常（Throwable）
* 内存释放不及时：重写了 finalize 方法的对象在第一次被 gc 时，并不能及时释放它占用的内存，因为要等着 FinalizerThread 调用完 finalize，把它从 unfinalized 队列移除后，第二次 gc 时才能真正释放内存
* 有的文章提到【Finalizer 线程会和我们的主线程进行竞争，不过由于它的优先级较低，获取到的CPU时间较少，因此它永远也赶不上主线程的步伐】这个显然是错误的，FinalizerThread 的优先级较普通线程更高，原因应该是 finalize 串行执行慢等原因综合导致

